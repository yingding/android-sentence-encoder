{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# create a model folder if it doesn't exist\n",
    "dir_name = 'model'\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download sentence encoder model from kaggle as tflite file\n",
    "import urllib.request\n",
    "url = 'https://www.kaggleusercontent.com/kf/39441989/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..X6Z3z3Z'\n",
    "file_name = os.path.join(dir_name, 'sentence_encoder_model.tflite')\n",
    "urllib.request.urlretrieve(url, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the USE TFLite model (replace with the path to your downloaded model)\n",
    "interpreter = tf.lite.Interpreter(model_path=\"universal_sentence_encoder_lite.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors information\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Prepare your sentences\n",
    "sentences = [\n",
    "    \"This is a sample sentence.\",\n",
    "    \"Another sentence with different meaning.\",\n",
    "    \"This sentence shares some similarity with the first one.\"\n",
    "]\n",
    "\n",
    "# Preprocess sentences (if required)\n",
    "# ...\n",
    "\n",
    "# Generate sentence embeddings\n",
    "embeddings = []\n",
    "for sentence in sentences:\n",
    "    # Convert sentence to a NumPy array\n",
    "    sentence_input = sentence.encode(\"utf-8\")  # Assuming text input\n",
    "\n",
    "    # Set input tensor\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], [sentence_input])\n",
    "\n",
    "    # Run inference\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Extract the embedding\n",
    "    embedding = interpreter.get_tensor(output_details[0][\"index\"])[0]\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Use the embeddings for various tasks like similarity comparison, clustering, etc.\n",
    "print(embeddings)  # Each embedding is a 512-dimensional vector\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm3.10",
   "language": "python",
   "name": "llm3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
